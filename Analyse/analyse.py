# -*- coding: utf-8 -*-
"""Analyse.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tk0doZKGnwwb4nyODgVDW48DK45tGkwZ
"""

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

# Load dataset
path = "/content/sample_data/california_housing_train.csv"
df = pd.read_csv(path)

df.head()

df.shape

df.info()

df.describe().T

df.isnull().sum()

num_cols = df.select_dtypes(include=np.number).columns

plt.figure(figsize=(16, 12))
for i, col in enumerate(num_cols, 1):
    plt.subplot(4, 4, i)
    sns.histplot(df[col], kde=True)
    plt.title(f"Distribution of {col}")
plt.tight_layout()
plt.show()

plt.figure(figsize=(14, 10))
sns.heatmap(df.corr(), annot=False, cmap="viridis")
plt.title("Correlation Heatmap")
plt.show()

top_features = df.corr()["median_house_value"].abs().sort_values(ascending=False).head(6).index
sns.pairplot(df[top_features])
plt.show()

plt.figure(figsize=(16, 10))
important = ["median_income", "total_rooms", "housing_median_age"]

for i, col in enumerate(important, 1):
    plt.subplot(2, 2, i)
    sns.scatterplot(x=df[col], y=df["median_house_value"])
    plt.title(f"{col} vs Median House Value")
plt.tight_layout()
plt.show()

plt.figure(figsize=(16, 12))
for i, col in enumerate(num_cols, 1):
    plt.subplot(4, 4, i)
    sns.boxplot(x=df[col])
    plt.title(f"Boxplot of {col}")
plt.tight_layout()
plt.show()

TARGET = "median_house_value"

X = df.drop(columns=[TARGET])
y = df[TARGET]

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42
)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

from sklearn.linear_model import LinearRegression

model_lr = LinearRegression()
model_lr.fit(X_train_scaled, y_train)

y_pred = model_lr.predict(X_test_scaled)

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Baseline Linear Regression Performance:")
print(f"RMSE: {rmse:.3f}")
print(f"MAE:  {mae:.3f}")
print(f"R²:   {r2:.3f}")

coeff = pd.DataFrame({
    "Feature": X.columns,
    "Coefficient": model_lr.coef_
}).sort_values("Coefficient", ascending=False)

coeff

import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

def evaluate_model(model, X_train, y_train, X_test, y_test):
    model.fit(X_train, y_train)
    preds = model.predict(X_test)

    rmse = np.sqrt(mean_squared_error(y_test, preds))
    mae  = mean_absolute_error(y_test, preds)
    r2   = r2_score(y_test, preds)

    return rmse, mae, r2


from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(
    n_estimators=300,
    max_depth=12,
    random_state=42
)

rf_rmse, rf_mae, rf_r2 = evaluate_model(
    rf, X_train_scaled, y_train, X_test_scaled, y_test
)

print("Random Forest Results:")
print("RMSE:", rf_rmse)
print("MAE :", rf_mae)
print("R²  :", rf_r2)